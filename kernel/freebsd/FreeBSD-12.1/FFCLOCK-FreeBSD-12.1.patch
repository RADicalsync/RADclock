diff -ar -U 2 --unidirectional-new-file /usr/src/sys/kern/kern_ffclock.c /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/kern_ffclock.c
--- /usr/src/sys/kern/kern_ffclock.c	2020-11-16 13:23:11.726722000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/kern_ffclock.c	2020-11-16 13:23:11.673193000 +1100
@@ -3,8 +3,7 @@
  *
  * Copyright (c) 2011 The University of Melbourne
- * All rights reserved.
  *
- * This software was developed by Julien Ridoux at the University of Melbourne
- * under sponsorship from the FreeBSD Foundation.
+ * This software was developed by Julien Ridoux and Darryl Veitch at the 
+ * University of Melbourne under sponsorship from the FreeBSD Foundation.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -31,5 +30,5 @@
 
 #include <sys/cdefs.h>
-__FBSDID("$FreeBSD: releng/12.1/sys/kern/kern_ffclock.c 326271 2017-11-27 15:20:12Z pfg $");
+__FBSDID("$FreeBSD$");
 
 #include "opt_ffclock.h"
@@ -93,16 +92,25 @@
 	/*
 	 * Leap second adjustment. Total as seen by synchronisation algorithm
-	 * since it started. cest.leapsec_next is the ffcounter prediction of
+	 * since it started. cest.leapsec_expected is the ffcounter prediction of
 	 * when the next leapsecond occurs.
 	 */
 	if ((flags & FFCLOCK_LEAPSEC) == FFCLOCK_LEAPSEC) {
-		bt->sec -= cest.leapsec_total;
-		if (ffc > cest.leapsec_next)
-			bt->sec -= cest.leapsec;
+		bt->sec -= cest.leapsec_total;	// subtracting means including leaps
+		if (cest.leapsec_expected != 0 && ffc > cest.leapsec_expected)
+			bt->sec -= cest.leapsec_next;
 	}
 
 	/* Boot time adjustment, for uptime/monotonic clocks. */
 	if ((flags & FFCLOCK_UPTIME) == FFCLOCK_UPTIME) {
-		bintime_sub(bt, &ffclock_boottime);
+		if ( bintime_cmp(&ffclock_boottime, bt, >) ) {	// would go -ve !
+			printf("** Uptime going -ve !  bt:  %llu.%lu  ffclock_boottime: %llu.%lu\n",
+					(unsigned long long)bt->sec,
+					(long unsigned)(bt->frac / MUS_AS_BINFRAC),
+					(unsigned long long)ffclock_boottime.sec,
+					(long unsigned)(ffclock_boottime.frac / MUS_AS_BINFRAC) );
+			bt->sec = 1;				// ensure Uptime >= 1 second
+			bt->frac = 0;
+		}
+			bintime_sub(bt, &ffclock_boottime);
 	}
 
@@ -111,10 +119,6 @@
 		ffdelta_error = ffc - cest.update_ffcount;
 		ffclock_convert_diff(ffdelta_error, error_bound);
-		/* 18446744073709 = int(2^64/1e12), err_bound_rate in [ps/s] */
-		bintime_mul(error_bound, cest.errb_rate *
-		    (uint64_t)18446744073709LL);
-		/* 18446744073 = int(2^64 / 1e9), since err_abs in [ns] */
-		bintime_addx(error_bound, cest.errb_abs *
-		    (uint64_t)18446744073LL);
+		bintime_mul(error_bound, cest.errb_rate * PS_AS_BINFRAC);	// errb_rate ps/s
+		bintime_addx(error_bound, cest.errb_abs * NS_AS_BINFRAC);	// errb_abs [ns]
 	}
 
@@ -145,6 +149,5 @@
 
 		ffclock_convert_diff(ffdelta, error_bound);
-		/* 18446744073709 = int(2^64/1e12), err_bound_rate in [ps/s] */
-		bintime_mul(error_bound, err_rate * (uint64_t)18446744073709LL);
+		bintime_mul(error_bound, err_rate * PS_AS_BINFRAC);	// err_rate in [ps/s]
 	}
 }
@@ -161,11 +164,11 @@
     "Feed-forward clock configuration");
 
-static char *sysclocks[] = {"feedback", "feed-forward"};
+static char *sysclocks[] = {"FBclock", "FFclock"};
 #define	MAX_SYSCLOCK_NAME_LEN 16
 #define	NUM_SYSCLOCKS nitems(sysclocks)
 
-static int ffclock_version = 2;
+static int ffclock_version = 3;
 SYSCTL_INT(_kern_sysclock_ffclock, OID_AUTO, version, CTLFLAG_RD,
-    &ffclock_version, 0, "Feed-forward clock kernel version");
+    &ffclock_version, 0, "FFclock kernel version");
 
 /* List available sysclocks. */
@@ -207,5 +210,6 @@
 	char newclock[MAX_SYSCLOCK_NAME_LEN];
 	int error;
-	int clk;
+	int clk=0;
+	int origclk=0;
 
 	/* Return the name of the current active sysclock. */
@@ -215,18 +219,19 @@
 	/* Check for error or no change */
 	if (error != 0 || req->newptr == NULL)
-		goto done;
+		return (error);
 
-	/* Change the active sysclock to the user specified one: */
+	/* Change the active sysclock to the user specified one */
 	error = EINVAL;
+	origclk = sysclock_active;
 	for (clk = 0; clk < NUM_SYSCLOCKS; clk++) {
-		if (strncmp(newclock, sysclocks[clk],
-		    MAX_SYSCLOCK_NAME_LEN - 1)) {
+		if (strncmp(newclock, sysclocks[clk], MAX_SYSCLOCK_NAME_LEN - 1))
 			continue;
-		}
 		sysclock_active = clk;
 		error = 0;
 		break;
 	}
-done:
+	if (sysclock_active != origclk)
+		printf("Active sysclock changed to %s \n", sysclocks[sysclock_active] );
+	
 	return (error);
 }
@@ -236,5 +241,5 @@
     "Name of the active system clock which is currently serving time");
 
-static int sysctl_kern_ffclock_ffcounter_bypass = 0;
+int sysctl_kern_ffclock_ffcounter_bypass=0;
 SYSCTL_INT(_kern_sysclock_ffclock, OID_AUTO, ffcounter_bypass, CTLFLAG_RW,
     &sysctl_kern_ffclock_ffcounter_bypass, 0,
@@ -247,5 +252,4 @@
 ffclock_bintime(struct bintime *bt)
 {
-
 	ffclock_abstime(NULL, bt, NULL, FFCLOCK_LERP | FFCLOCK_LEAPSEC);
 }
@@ -272,5 +276,4 @@
 ffclock_getbintime(struct bintime *bt)
 {
-
 	ffclock_abstime(NULL, bt, NULL,
 	    FFCLOCK_LERP | FFCLOCK_LEAPSEC | FFCLOCK_FAST);
@@ -432,4 +435,5 @@
 	ffclock_updated++;
 	mtx_unlock(&ffclock_mtx);
+	
 	return (error);
 }
@@ -464,5 +468,4 @@
 sys_ffclock_getcounter(struct thread *td, struct ffclock_getcounter_args *uap)
 {
-
 	return (ENOSYS);
 }
@@ -471,5 +474,4 @@
 sys_ffclock_setestimate(struct thread *td, struct ffclock_setestimate_args *uap)
 {
-
 	return (ENOSYS);
 }
@@ -478,5 +480,4 @@
 sys_ffclock_getestimate(struct thread *td, struct ffclock_getestimate_args *uap)
 {
-
 	return (ENOSYS);
 }
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/kern/kern_tc.c /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/kern_tc.c
--- /usr/src/sys/kern/kern_tc.c	2020-11-16 13:23:11.727034000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/kern_tc.c	2020-11-16 13:23:11.673518000 +1100
@@ -10,8 +10,7 @@
  *
  * Copyright (c) 2011, 2015, 2016 The FreeBSD Foundation
- * All rights reserved.
  *
- * Portions of this software were developed by Julien Ridoux at the University
- * of Melbourne under sponsorship from the FreeBSD Foundation.
+ * Portions of this software were developed by Julien Ridoux and Darryl Veitch
+ * at the University of Melbourne under sponsorship from the FreeBSD Foundation.
  *
  * Portions of this software were developed by Konstantin Belousov
@@ -546,4 +545,6 @@
 	struct bintime		tick_time;
 	struct bintime		tick_time_lerp;
+	struct bintime		tick_time_diff;
+	struct bintime		tick_error;
 	ffcounter		tick_ffcount;
 	uint64_t		period_lerp;
@@ -572,47 +573,15 @@
 	ffclock_updated = 0;
 	ffclock_status = FFCLOCK_STA_UNSYNC;
+	ffclock_boottime.sec = ffclock_boottime.frac = 0;
 	mtx_init(&ffclock_mtx, "ffclock lock", NULL, MTX_DEF);
 }
 
-/*
- * Reset the feed-forward clock estimates. Called from inittodr() to get things
- * kick started and uses the timecounter nominal frequency as a first period
- * estimate. Note: this function may be called several time just after boot.
- * Note: this is the only function that sets the value of boot time for the
- * monotonic (i.e. uptime) version of the feed-forward clock.
- */
-void
-ffclock_reset_clock(struct timespec *ts)
-{
-	struct timecounter *tc;
-	struct ffclock_estimate cest;
 
-	tc = timehands->th_counter;
-	memset(&cest, 0, sizeof(struct ffclock_estimate));
-
-	timespec2bintime(ts, &ffclock_boottime);
-	timespec2bintime(ts, &(cest.update_time));
-	ffclock_read_counter(&cest.update_ffcount);
-	cest.leapsec_next = 0;
-	cest.period = ((1ULL << 63) / tc->tc_frequency) << 1;
-	cest.errb_abs = 0;
-	cest.errb_rate = 0;
-	cest.status = FFCLOCK_STA_UNSYNC;
-	cest.leapsec_total = 0;
-	cest.leapsec = 0;
-
-	mtx_lock(&ffclock_mtx);
-	bcopy(&cest, &ffclock_estimate, sizeof(struct ffclock_estimate));
-	ffclock_updated = INT8_MAX;
-	mtx_unlock(&ffclock_mtx);
-
-	printf("ffclock reset: %s (%llu Hz), time = %ld.%09lu\n", tc->tc_name,
-	    (unsigned long long)tc->tc_frequency, (long)ts->tv_sec,
-	    (unsigned long)ts->tv_nsec);
-}
-
 /*
  * Sub-routine to convert a time interval measured in RAW counter units to time
- * in seconds stored in bintime format.
+ * in seconds stored in binary fraction units, when the time interval may be
+ * over one second.  If is is guaranteed to be under a second, then
+ *   bintime_addx(bt, period * ffdelta);
+ * should be used instead.
  * NOTE: bintime_mul requires u_int, but the value of the ffcounter may be
  * larger than the max value of u_int (on 32 bit architecture). Loop to consume
@@ -640,85 +609,213 @@
 }
 
+
 /*
- * Update the fftimehands.
- * Push the tick ffcount and time(s) forward based on current clock estimate.
- * The conversion from ffcounter to bintime relies on the difference clock
- * principle, whose accuracy relies on computing small time intervals. If a new
- * clock estimate has been passed by the synchronisation daemon, make it
- * current, and compute the linear interpolation for monotonic time if needed.
+ * Update the fftimehands. The updated tick state is based on the previous tick if
+ * there has been no actionable update in the FFclock parameters during the current
+ * tick (ffclock_updated <= 0), and each of the native, monotonic, and difference
+ * FFclocks advance linearly. Otherwise it is based off the updated parameters at
+ * the time of the update. The native FFclock will then jump, the monotonic clock
+ * will not (except under special conditions).  The diff clock will never
+ * jump, to ensure its intended use as a difference clock, used to measure
+ * time differences. The linear interpolation parameters of the
+ * monotonic FFclock ({tick_time,period}_lerp) are recomputed for the new tick.
+ *
+ * The instant defining the start of the new tick is the  delta=tc_delta call
+ *	from tc_windup. This is simply mirrored here in the FF counter `read'.
+ *
+ * If a RTC reset occurs, then tc_windup is called within tc_setclock with a
+ * bootime argument, passed here as reset_FBbootime. If non-NULL, FFclocks are
+ * reset using this and the UTC reset calculated in tc_windup, and FFdata is
+ * reinitialized to basic values.
  */
 static void
-ffclock_windup(unsigned int delta)
+ffclock_windup(unsigned int delta, struct bintime *reset_FBbootime,
+					struct bintime *reset_UTC)
 {
 	struct ffclock_estimate *cest;
 	struct fftimehands *ffth;
-	struct bintime bt, gap_lerp;
+	struct bintime bt, gap_lerp, upt;
 	ffcounter ffdelta;
 	uint64_t frac;
-	unsigned int polling;
 	uint8_t forward_jump, ogen;
 
-	/*
-	 * Pick the next timehand, copy current ffclock estimates and move tick
-	 * times and counter forward.
-	 */
 	forward_jump = 0;
+	
+	/* Prepare next fftimehand where tick state will be updated */
 	ffth = fftimehands->next;
 	ogen = ffth->gen;
 	ffth->gen = 0;
 	cest = &ffth->cest;
-	bcopy(&fftimehands->cest, cest, sizeof(struct ffclock_estimate));
+
+	/* Move FF counter forward to existing tick start */
 	ffdelta = (ffcounter)delta;
-	ffth->period_lerp = fftimehands->period_lerp;
+	ffth->tick_ffcount = fftimehands->tick_ffcount + ffdelta;
 
-	ffth->tick_time = fftimehands->tick_time;
-	ffclock_convert_delta(ffdelta, cest->period, &bt);
-	bintime_add(&ffth->tick_time, &bt);
+	/*
+	 * RTC reset: reset all FFclocks, and the global FFdata.
+	 * The period is initialized only if needed.
+	 */
+	if (reset_FBbootime) {
+		memcpy(cest, &ffclock_estimate, sizeof(struct ffclock_estimate));
+		
+		/*
+		 * Determine value of ffclock_boottime to maximize Upclock continuity.
+		 * sysclock = FB :  kernel will not see a jump now, better to align FF
+		 *                  and FB to minimize jump if sysclock changes
+		 *          = FF :  ensure continuity in FF and hence sysclock Uptime
+		 */
+		if (sysclock_active == SYSCLOCK_FB)
+			ffclock_boottime = *reset_FBbootime;
+		else {
+			/* First calculate what uptime would be at tick start, if not reset */
+			ffth->tick_time_lerp = fftimehands->tick_time_lerp;
+			ffclock_convert_delta(ffdelta, ffth->period_lerp, &bt);
+			bintime_add(&ffth->tick_time_lerp, &bt);
 
-	ffth->tick_time_lerp = fftimehands->tick_time_lerp;
-	ffclock_convert_delta(ffdelta, ffth->period_lerp, &bt);
-	bintime_add(&ffth->tick_time_lerp, &bt);
+			/* Cancel out jump in UTC due to reset */
+			bintime_clear(&gap_lerp);
+			if (bintime_cmp(reset_UTC, &ffth->tick_time_lerp, >)) {
+				gap_lerp = *reset_UTC;
+				bintime_sub(&gap_lerp, &ffth->tick_time_lerp);
+				bintime_add(&ffclock_boottime, &gap_lerp);
+			} else {
+				gap_lerp = ffth->tick_time_lerp;
+				bintime_sub(&gap_lerp, reset_UTC);
+				bintime_sub(&ffclock_boottime, &gap_lerp);
+			}
+		}
 
-	ffth->tick_ffcount = fftimehands->tick_ffcount + ffdelta;
+		/* For UTC clocks, align FF to the FB reset derived from the RTC reset */
+		ffth->tick_time = *reset_UTC;
+		ffth->tick_time_lerp = *reset_UTC;
+		ffth->tick_time_diff = *reset_UTC;
 
+		/* Reset FFdata to reflect the reset, taken to occur at tick-start. */
+		cest->update_time = *reset_UTC;
+		cest->update_ffcount = ffth->tick_ffcount;
+		if (cest->period == 0)		// if never set
+			cest->period = ((1ULL << 63)/ timehands->th_counter->tc_frequency) << 1;
+
+		cest->errb_abs = 0;
+		cest->errb_rate = 0;
+		cest->status = FFCLOCK_STA_UNSYNC;
+		cest->secs_to_nextupdate = 0;		// signals no daemon update since reset
+		cest->leapsec_expected = 0;
+		cest->leapsec_total = 0;
+		cest->leapsec_next = 0;
+		mtx_lock(&ffclock_mtx);
+		memcpy(&ffclock_estimate, cest, sizeof(struct ffclock_estimate));
+		ffclock_updated = 0;		// signal no daemon update to process
+		mtx_unlock(&ffclock_mtx);
+
+		ffclock_status = FFCLOCK_STA_UNSYNC;
+
+		/* Reset remaining fftimehands members */
+		ffth->tick_error.sec = ffth->tick_error.frac = 0;
+		ffth->period_lerp = cest->period;
+
+		upt = ffth->tick_time_lerp;
+		bintime_sub(&upt, &ffclock_boottime);
+		printf("FFclock processing RTC reset: UTC: %ld.%03lu"
+				 " boottime: %llu.%03lu, uptime preserved at: %llu.%03lu\n",
+				(long)ffth->tick_time_lerp.sec,
+				(unsigned long)(ffth->tick_time_lerp.frac / MS_AS_BINFRAC),
+				(unsigned long long)ffclock_boottime.sec,
+				(long unsigned)(ffclock_boottime.frac / MS_AS_BINFRAC),
+				(unsigned long long)upt.sec,
+				(long unsigned)(upt.frac / MS_AS_BINFRAC) );
+
+	}
+
+
+
 	/*
-	 * Assess the status of the clock, if the last update is too old, it is
-	 * likely the synchronisation daemon is dead and the clock is free
-	 * running.
+	 * Signal to ignore a stale (pre-reset) daemon update following a RTC reset.
 	 */
-	if (ffclock_updated == 0) {
-		ffdelta = ffth->tick_ffcount - cest->update_ffcount;
-		ffclock_convert_delta(ffdelta, cest->period, &bt);
-		if (bt.sec > 2 * FFCLOCK_SKM_SCALE)
-			ffclock_status |= FFCLOCK_STA_UNSYNC;
+	if (ffclock_updated > 0 && fftimehands->cest.secs_to_nextupdate == 0
+									&& bintime_cmp(&fftimehands->cest.update_time, \
+														&ffclock_estimate.update_time,>) ) {
+		ffclock_updated = 0;
+		printf("Ignoring stale FFdata update following RTC reset.\n");
 	}
 
+
 	/*
-	 * If available, grab updated clock estimates and make them current.
-	 * Recompute time at this tick using the updated estimates. The clock
-	 * estimates passed the feed-forward synchronisation daemon may result
-	 * in time conversion that is not monotonically increasing (just after
-	 * the update). time_lerp is a particular linear interpolation over the
-	 * synchronisation algo polling period that ensures monotonicity for the
-	 * clock ids requesting it.
+	 * No acceptable update in FFclock parameters to process.
+	 * Includes case of daemon update following a RTC reset that must be ignored.
+	 * Tick state update based on copy or simple projection from previous tick.
 	 */
+	if (ffclock_updated <= 0 && reset_FBbootime == NULL) {
+
+		/* Update native FFclock members {cest, tick_time{_diff}, tick_error} */
+		memcpy(cest, &fftimehands->cest, sizeof(struct ffclock_estimate));
+		ffth->tick_time		= fftimehands->tick_time;
+		ffth->tick_time_diff = fftimehands->tick_time_diff;
+		ffclock_convert_delta(ffdelta, cest->period, &bt);
+		bintime_add(&ffth->tick_time, &bt);
+		bintime_add(&ffth->tick_time_diff, &bt);
+		bintime_mul(&bt, cest->errb_rate * PS_AS_BINFRAC);	// errb_rate in [ps/s]
+		bintime_add(&ffth->tick_error, &bt);
+
+		/* Update mono FFclock members {period_lerp, tick_time_lerp} */
+		ffth->period_lerp 	= fftimehands->period_lerp;
+		ffth->tick_time_lerp = fftimehands->tick_time_lerp;
+		ffclock_convert_delta(ffdelta, ffth->period_lerp, &bt);
+		bintime_add(&ffth->tick_time_lerp, &bt);
+
+		/* Check if the clock status should be set to unsynchronized.
+		 * Assessment based on age of last/current update, and the daemon's
+		 * estimate of the wait to the next update.
+		 * If the daemon's UNSYNC status is deemed too stale, it is over-ridden.
+		 */
+		if (ffclock_updated == 0) {
+			bt = ffth->tick_time;
+			bintime_sub(&bt, &cest->update_time);	// bt = now - timeoflastupdate
+			if (bt.sec > 3 * FFCLOCK_SKM_SCALE &&
+			    bt.sec > 3 * cest->secs_to_nextupdate)
+				ffclock_status |= FFCLOCK_STA_UNSYNC;
+		}
+		
+	}
+	
+	/*
+	 * An update in FFclock parameters is available in this tick.
+	 * Generate the new tick state based on this, projected from the update time.
+	 */
 	if (ffclock_updated > 0) {
-		bcopy(&ffclock_estimate, cest, sizeof(struct ffclock_estimate));
-		ffdelta = ffth->tick_ffcount - cest->update_ffcount;
+
+		/* Update native FFclock members {cest, tick_time, tick_error} */
+		memcpy(cest, &ffclock_estimate, sizeof(struct ffclock_estimate));
+		ffdelta = ffth->tick_ffcount - cest->update_ffcount; // time since update
 		ffth->tick_time = cest->update_time;
 		ffclock_convert_delta(ffdelta, cest->period, &bt);
 		bintime_add(&ffth->tick_time, &bt);
+		bintime_mul(&bt, cest->errb_rate * PS_AS_BINFRAC);	// errb_rate in [ps/s]
+		bintime_addx(&bt, cest->errb_abs * NS_AS_BINFRAC);	// errb_abs in [ns]
+		ffth->tick_error = bt;
 
-		/* ffclock_reset sets ffclock_updated to INT8_MAX */
-		if (ffclock_updated == INT8_MAX)
-			ffth->tick_time_lerp = ffth->tick_time;
+		/*
+		 * Update native FF difference clock member {tick_time_diff},
+		 * ensuring continuity over ticks.
+		 */
+		ffth->tick_time_diff = fftimehands->tick_time_diff;
+		ffclock_convert_delta((ffcounter)delta, cest->period, &bt);
+		bintime_add(&ffth->tick_time_diff, &bt);
 
-		if (bintime_cmp(&ffth->tick_time, &ffth->tick_time_lerp, >))
-			forward_jump = 1;
-		else
-			forward_jump = 0;
+		/*
+		 * Update mono FFclock member tick_time_lerp, standard case,
+		 * ensuring continuity over ticks.
+		 */
+		ffth->tick_time_lerp = fftimehands->tick_time_lerp;
+		ffclock_convert_delta((ffcounter)delta, fftimehands->period_lerp, &bt);
+		bintime_add(&ffth->tick_time_lerp, &bt);
 
+		/* Record dirn of jump between monoFFclock and FFclock at tick-start */
+      if (bintime_cmp(&ffth->tick_time, &ffth->tick_time_lerp, >))
+			forward_jump = 1;		// else = 0
+
+		/* Record magnitude of jump */
 		bintime_clear(&gap_lerp);
-		if (forward_jump) {
+		if (forward_jump) {		// monoFFclock < FFclock
 			gap_lerp = ffth->tick_time;
 			bintime_sub(&gap_lerp, &ffth->tick_time_lerp);
@@ -729,50 +826,72 @@
 
 		/*
-		 * The reset from the RTC clock may be far from accurate, and
-		 * reducing the gap between real time and interpolated time
-		 * could take a very long time if the interpolated clock insists
-		 * on strict monotonicity. The clock is reset under very strict
-		 * conditions (kernel time is known to be wrong and
-		 * synchronization daemon has been restarted recently.
-		 * ffclock_boottime absorbs the jump to ensure boot time is
-		 * correct and uptime functions stay consistent.
+		 * Update mono FFclock member tick_time_lerp, exceptional case.
+		 * Break monotonicity by allowing monoFFclock jump to meet native FFclock
+		 * Only occurs under tight conditions to prevent a poor monoFFclock
+		 * initialization from taking a very long time to catch up to FFclock.
+		 * Absorb the jump into ffclock_boottime to ensure continuity of
+		 * uptime functions.
 		 */
 		if (((ffclock_status & FFCLOCK_STA_UNSYNC) == FFCLOCK_STA_UNSYNC) &&
-		    ((cest->status & FFCLOCK_STA_UNSYNC) == 0) &&
-		    ((cest->status & FFCLOCK_STA_WARMUP) == FFCLOCK_STA_WARMUP)) {
-			if (forward_jump)
+		    ((cest->status & FFCLOCK_STA_UNSYNC) == 0) ) {
+			if (forward_jump) {
+				printf("ffwindup:  Jumping monotonic FFclock forward by %llu.%03lu [s]",
+							(unsigned long long)gap_lerp.sec,
+			 				(long unsigned)(gap_lerp.frac / MS_AS_BINFRAC) );
 				bintime_add(&ffclock_boottime, &gap_lerp);
-			else
+			} else {
+				printf("ffwindup:  Jumping monotonic FFclock backward by %llu.%03lu",
+							(unsigned long long)gap_lerp.sec,
+			 				(long unsigned)(gap_lerp.frac / MS_AS_BINFRAC) );
 				bintime_sub(&ffclock_boottime, &gap_lerp);
+			}
+
 			ffth->tick_time_lerp = ffth->tick_time;
-			bintime_clear(&gap_lerp);
+
+			upt = ffth->tick_time_lerp;
+			bintime_sub(&upt, &ffclock_boottime);
+			printf(" (uptime preserved at: %llu.%03lu)\n",
+							(unsigned long long)upt.sec,
+			 				(long unsigned)(upt.frac / MS_AS_BINFRAC) );
+			 				
+			bintime_clear(&gap_lerp); // signal nothing to do to period_lerp algo
 		}
 
-		ffclock_status = cest->status;
-		ffth->period_lerp = cest->period;
 
 		/*
-		 * Compute corrected period used for the linear interpolation of
-		 * time. The rate of linear interpolation is capped to 5000PPM
-		 * (5ms/s).
+		 * Update mono FFclock member period_lerp
+		 * The goal of the monoFF algorithm is to reduce the gap between monoFF and the
+		 * native FF to zero by the next FFclock update. The reduction uses linear
+		 * interpolation via selecting period_lerp.  To ensure rate quality,
+		 * |period_lerp - period| is capped to 5000PPM (5ms/s).
+		 * If there is no gap, the clocks will agree throughout the new tick.
 		 */
-		if (bintime_isset(&gap_lerp)) {
-			ffdelta = cest->update_ffcount;
-			ffdelta -= fftimehands->cest.update_ffcount;
-			ffclock_convert_delta(ffdelta, cest->period, &bt);
-			polling = bt.sec;
+		ffth->period_lerp = cest->period;   // re-initialize
+
+		/* Keep default if no (or negligible) gap or no daemon updates yet */
+		if (bintime_isset(&gap_lerp) && cest->secs_to_nextupdate > 0) {
+
+			/* Calculate cap */
 			bt.sec = 0;
-			bt.frac = 5000000 * (uint64_t)18446744073LL;
-			bintime_mul(&bt, polling);
+			bt.frac = 5000000 * NS_AS_BINFRAC;
+			bintime_mul(&bt, cest->secs_to_nextupdate);
+
+			/* Determine the amount of gap to close over the next update interval */
 			if (bintime_cmp(&gap_lerp, &bt, >))
-				gap_lerp = bt;
+				gap_lerp = bt;		// gap_lerp = min(gap_lerp, bt)
 
-			/* Approximate 1 sec by 1-(1/2^64) to ease arithmetic */
+			/* Convert secs_to_nextupdate to counter units */
 			frac = 0;
+			frac -= 1;		// approximate 2^64 with (2^64)-1 to ease arithmetic
+			ffdelta = (frac / cest->period) * cest->secs_to_nextupdate;
+
+			/* Store the portion of gap per cycle in frac */
+			frac = 0;
 			if (gap_lerp.sec > 0) {
 				frac -= 1;
 				frac /= ffdelta / gap_lerp.sec;
+				//frac = (cest->period * gap_lerp.sec) / cest->secs_to_nextupdate;
 			}
-			frac += gap_lerp.frac / ffdelta;
+			frac += gap_lerp.frac / ffdelta;	// very small gaps rounded to zero
 
 			if (forward_jump)
@@ -780,26 +899,29 @@
 			else
 				ffth->period_lerp -= frac;
+
 		}
 
-		ffclock_updated = 0;
+		ffclock_status = cest->status;	// unsets FFCLOCK_STA_UNSYNC
+		ffclock_updated = 0;		// signal that latest update processed
 	}
+
+	/* Bump generation of new tick, avoiding the reserved 0 value */
 	if (++ogen == 0)
 		ogen = 1;
 	ffth->gen = ogen;
+
 	fftimehands = ffth;
+
 }
 
+
 /*
  * Adjust the fftimehands when the timecounter is changed. Stating the obvious,
- * the old and new hardware counter cannot be read simultaneously. tc_windup()
- * does read the two counters 'back to back', but a few cycles are effectively
- * lost, and not accumulated in tick_ffcount. This is a fairly radical
- * operation for a feed-forward synchronization daemon, and it is its job to not
- * pushing irrelevant data to the kernel. Because there is no locking here,
- * simply force to ignore pending or next update to give daemon a chance to
- * realize the counter has changed.
+ * the old and new hardware counter cannot be read simultaneously.
+ * Because there is no locking here, simply force to ignore pending or next
+ * update to give daemon a chance to realize the counter has changed.
  */
 static void
-ffclock_change_tc(struct timehands *th)
+ffclock_change_tc(struct timehands *th, u_int ncount)
 {
 	struct fftimehands *ffth;
@@ -807,29 +929,71 @@
 	struct timecounter *tc;
 	uint8_t ogen;
+	ffcounter now;
 
 	tc = th->th_counter;
+	
+	/* Prepare next fftimehand where tick state will be updated */
 	ffth = fftimehands->next;
 	ogen = ffth->gen;
 	ffth->gen = 0;
-
 	cest = &ffth->cest;
-	bcopy(&(fftimehands->cest), cest, sizeof(struct ffclock_estimate));
+	
+	/*
+	 * Reset FFcounter to match start of current tick.
+	 *  If a TSC derived counter, get correct higher order bits to ensure the
+	 *  FFcounter origin matches that of the counter, rather than the time the
+	 *  counter was adopted. If not TSC, the origin will be ncount in the past.
+	 *  In all cases, the lower bits of FFcounter and th_offset_count will agree.
+	 */
+	if ( strcmp(tc->tc_name, "TSC") != 0 )
+		ffth->tick_ffcount = (ffcounter)ncount;  // origin matches timehands
+	else {
+		now = (ffcounter) rdtsc();
+		if (strcmp(tc->tc_name, "TSC-low") == 0) // TSC reads are shifted
+			now >>= (int)(intptr_t)tc->tc_priv;
+		/* reconstruct the counter value at the time ncount was taken */
+		ffth->tick_ffcount = now - (ffcounter)((u_int)now - ncount);
+	}
+	
+	/*
+	 * This update does not advance the tick itself, intead it reinitiates when
+	 * existing values are not appropriate for the new counter.
+	 * NOte cest->update_{time,ffcount} are still valid as a record of when the
+	 * data was changed, wrt the new counter.
+	 */
+	memcpy(cest, &(fftimehands->cest), sizeof(struct ffclock_estimate));
+	cest->update_ffcount = ffth->tick_ffcount;
+	cest->secs_to_nextupdate = 0;
 	cest->period = ((1ULL << 63) / tc->tc_frequency ) << 1;
 	cest->errb_abs = 0;
 	cest->errb_rate = 0;
 	cest->status |= FFCLOCK_STA_UNSYNC;
+	cest->leapsec_expected = 0;
+	cest->leapsec_total = 0;
+	cest->leapsec_next = 0;
 
-	ffth->tick_ffcount = fftimehands->tick_ffcount;
-	ffth->tick_time_lerp = fftimehands->tick_time_lerp;
 	ffth->tick_time = fftimehands->tick_time;
+	ffth->tick_error = fftimehands->tick_error;
+	ffth->tick_time_diff = fftimehands->tick_time_diff;
+	ffth->tick_time_lerp = fftimehands->tick_time_lerp;
 	ffth->period_lerp = cest->period;
+	
+	/* Push the reset FFdata to the global variable */
+	mtx_lock(&ffclock_mtx);
+	memcpy(&ffclock_estimate, cest, sizeof(struct ffclock_estimate));
+	mtx_unlock(&ffclock_mtx);
 
 	/* Do not lock but ignore next update from synchronization daemon. */
 	ffclock_updated--;
-
+	
 	if (++ogen == 0)
 		ogen = 1;
 	ffth->gen = ogen;
 	fftimehands = ffth;
+	
+	printf("ffclock_change_tc: new tick_ffcount = %llu = %#llX, with tc %s (%llu Hz)\n",
+		(unsigned long long)ffth->tick_ffcount,
+		(unsigned long long)ffth->tick_ffcount,
+		tc->tc_name, (unsigned long long)tc->tc_frequency);
 }
 
@@ -843,8 +1007,5 @@
 	uint8_t gen;
 
-	/*
-	 * No locking but check generation has not changed. Also need to make
-	 * sure ffdelta is positive, i.e. ffcount > tick_ffcount.
-	 */
+	/* No locking but check generation has not changed. */
 	do {
 		ffth = fftimehands;
@@ -873,8 +1034,5 @@
 	uint8_t gen;
 
-	/*
-	 * No locking but check generation has not changed. Also need to make
-	 * sure ffdelta is positive, i.e. ffcount > tick_ffcount.
-	 */
+	/* No locking but check generation has not changed */
 	do {
 		ffth = fftimehands;
@@ -922,4 +1080,5 @@
 /*
  * Access to current ffcounter value.
+ * If bypass mode on, assume the counter is TSC, and access it directly.
  */
 void
@@ -930,4 +1089,9 @@
 	unsigned int gen, delta;
 
+	if (sysctl_kern_ffclock_ffcounter_bypass == 1) {
+		*ffcount = (ffcounter) rdtsc();
+		return;
+	}
+	
 	/*
 	 * ffclock_windup() called from tc_windup(), safe to rely on
@@ -1055,5 +1219,5 @@
  * when the FFCLOCK option is defined.
  */
-int sysclock_active = SYSCLOCK_FBCK;
+int sysclock_active = SYSCLOCK_FB;
 
 /* Internal NTP status and error estimates. */
@@ -1062,6 +1226,8 @@
 
 /*
- * Take a snapshot of sysclock data which can be used to compare system clocks
- * and generate timestamps after the fact.
+ * Take a raw timestamp (timecounter reading), and then snapshot the sysclock
+ * data which can be used to compare system clocks and generate timestamps
+ * of all possible types after the fact.
+ * If bypass mode on, assume the counter is TSC, and access it directly.
  */
 void
@@ -1073,23 +1239,29 @@
 	unsigned int delta, gen;
 #ifdef FFCLOCK
-	ffcounter ffcount;
-	struct fftimehands *ffth;
 	struct ffclock_info *ffi;
+	struct fftimehands *ffth;
 	struct ffclock_estimate cest;
-
-	ffi = &clock_snap->ff_info;
 #endif
 
-	fbi = &clock_snap->fb_info;
 	delta = 0;
-
 	do {
 		th = timehands;
 		gen = atomic_load_acq_int(&th->th_generation);
+		if (!fast) {
+#ifdef FFCLOCK
+			if (sysctl_kern_ffclock_ffcounter_bypass == 1)
+				delta = rdtsc32() - th->th_offset_count;
+			else
+#endif
+				delta = tc_delta(th);
+		}
+		fbi = &clock_snap->fb_info;
 		fbi->th_scale = th->th_scale;
 		fbi->tick_time = th->th_offset;
 #ifdef FFCLOCK
+		ffi = &clock_snap->ff_info;
 		ffth = fftimehands;
-		ffi->tick_time = ffth->tick_time_lerp;
+		ffi->tick_time = ffth->tick_time;
+		ffi->tick_time_diff = ffth->tick_time_diff;
 		ffi->tick_time_lerp = ffth->tick_time_lerp;
 		ffi->period = ffth->cest.period;
@@ -1098,6 +1270,4 @@
 		cest = ffth->cest;
 #endif
-		if (!fast)
-			delta = tc_delta(th);
 		atomic_thread_fence_acq();
 	} while (gen == 0 || gen != th->th_generation);
@@ -1107,10 +1277,9 @@
 
 	/* Record feedback clock status and error. */
-	clock_snap->fb_info.status = time_status;
+	fbi->status = time_status;
 	/* XXX: Very crude estimate of feedback clock error. */
-	bt.sec = time_esterror / 1000000;
-	bt.frac = ((time_esterror - bt.sec) * 1000000) *
-	    (uint64_t)18446744073709ULL;
-	clock_snap->fb_info.error = bt;
+	bt.sec = time_esterror / 1000000;			// time_esterror is in mus
+	bt.frac = (time_esterror - bt.sec * 1000000) * MUS_AS_BINFRAC;
+	fbi->error = bt;
 
 #ifdef FFCLOCK
@@ -1118,18 +1287,19 @@
 		clock_snap->ffcount += delta;
 
-	/* Record feed-forward clock leap second adjustment. */
+	/* Precalculate total leap second adjustment appropriate to this ffcount.
+	 * Includes total leaps so far and impending leap ffcount may have surpassed.
+	 */
 	ffi->leapsec_adjustment = cest.leapsec_total;
-	if (clock_snap->ffcount > cest.leapsec_next)
-		ffi->leapsec_adjustment -= cest.leapsec;
+	if (cest.leapsec_expected != 0 && clock_snap->ffcount > cest.leapsec_expected)
+		ffi->leapsec_adjustment += cest.leapsec_next;
 
 	/* Record feed-forward clock status and error. */
-	clock_snap->ff_info.status = cest.status;
-	ffcount = clock_snap->ffcount - cest.update_ffcount;
-	ffclock_convert_delta(ffcount, cest.period, &bt);
-	/* 18446744073709 = int(2^64/1e12), err_bound_rate in [ps/s]. */
-	bintime_mul(&bt, cest.errb_rate * (uint64_t)18446744073709ULL);
-	/* 18446744073 = int(2^64 / 1e9), since err_abs in [ns]. */
-	bintime_addx(&bt, cest.errb_abs * (uint64_t)18446744073ULL);
-	clock_snap->ff_info.error = bt;
+	ffi->status = cest.status;
+	ffi->error = ffth->tick_error;
+	if (!fast) {
+		ffclock_convert_delta((ffcounter)delta, cest.period, &bt);
+		bintime_mul(&bt, cest.errb_rate * PS_AS_BINFRAC);	// errb_rate in [ps/s]
+		bintime_add(&ffi->error, &bt);
+	}
 #endif
 }
@@ -1137,9 +1307,10 @@
 /*
  * Convert a sysclock snapshot into a struct bintime based on the specified
- * clock source and flags.
+ * clock paradigm, and flags.
+ * wantUptime and wantLerp supercede wantDiff if (erroneously) used together
  */
 int
 sysclock_snap2bintime(struct sysclock_snap *cs, struct bintime *bt,
-    int whichclock, uint32_t flags)
+    int whichclock, int wantFast, int wantUptime, int wantLerp, int wantDiff)
 {
 	struct bintime boottimebin;
@@ -1150,12 +1321,13 @@
 
 	switch (whichclock) {
-	case SYSCLOCK_FBCK:
+	case SYSCLOCK_FB:
 		*bt = cs->fb_info.tick_time;
 
 		/* If snapshot was created with !fast, delta will be >0. */
-		if (cs->delta > 0)
+		if (!wantFast && cs->delta > 0)
 			bintime_addx(bt, cs->fb_info.th_scale * cs->delta);
 
-		if ((flags & FBCLOCK_UPTIME) == 0) {
+		/* Native FBclock is Uptime, need to adjust if want UTC */
+		if (!wantUptime) {
 			getboottimebin(&boottimebin);
 			bintime_add(bt, &boottimebin);
@@ -1163,26 +1335,29 @@
 		break;
 #ifdef FFCLOCK
-	case SYSCLOCK_FFWD:
-		if (flags & FFCLOCK_LERP) {
-			*bt = cs->ff_info.tick_time_lerp;
+	case SYSCLOCK_FF:
+		if (wantLerp) {	// Lerp supercedes Diff
 			period = cs->ff_info.period_lerp;
+			*bt = cs->ff_info.tick_time_lerp;
 		} else {
-			*bt = cs->ff_info.tick_time;
 			period = cs->ff_info.period;
+			if (wantDiff)
+				*bt = cs->ff_info.tick_time_diff;
+			else
+				*bt = cs->ff_info.tick_time;
 		}
 
 		/* If snapshot was created with !fast, delta will be >0. */
-		if (cs->delta > 0) {
-			ffclock_convert_delta(cs->delta, period, &bt2);
+		if (!wantFast && cs->delta > 0) {
+			ffclock_convert_delta((ffcounter)cs->delta, period, &bt2);
 			bintime_add(bt, &bt2);
 		}
 
-		/* Leap second adjustment. */
-		if (flags & FFCLOCK_LEAPSEC)
-			bt->sec -= cs->ff_info.leapsec_adjustment;
-
-		/* Boot time adjustment, for uptime/monotonic clocks. */
-		if (flags & FFCLOCK_UPTIME)
+		/* Add appropriate constant to create Uptime, UTC, or Diff FF clock */
+		if (wantUptime) // Uptime superceded Diff
 			bintime_sub(bt, &ffclock_boottime);
+		else
+			if (!wantDiff)				 // UTC
+				bt->sec -= cs->ff_info.leapsec_adjustment;
+			// else Diff
 		break;
 #endif
@@ -1295,4 +1470,6 @@
  * Step our concept of UTC.  This is done by modifying our estimate of
  * when we booted.
+ * Since this function sets the FB clock, if FFCLOCK defined, ensure all
+ * timestamp calls are in fact from the FB clock for consistency.
  */
 void
@@ -1303,8 +1480,16 @@
 
 	timespec2bintime(ts, &bt);
+#ifdef FFCLOCK
+	fbclock_nanotime(&tbef);
+#else
 	nanotime(&tbef);
+#endif
 	mtx_lock_spin(&tc_setclock_mtx);
 	cpu_tick_calibrate(1);
+#ifdef FFCLOCK
+	fbclock_binuptime(&bt2);
+#else
 	binuptime(&bt2);
+#endif
 	bintime_sub(&bt, &bt2);
 
@@ -1317,5 +1502,9 @@
 	sleepq_chains_remove_matching(sleeping_on_old_rtc);
 	if (timestepwarnings) {
+#ifdef FFCLOCK
+		fbclock_nanotime(&taft);
+#else
 		nanotime(&taft);
+#endif
 		log(LOG_INFO,
 		    "Time stepped from %jd.%09ld to %jd.%09ld (%jd.%09ld)\n",
@@ -1369,7 +1558,5 @@
 	else
 		ncount = 0;
-#ifdef FFCLOCK
-	ffclock_windup(delta);
-#endif
+
 	th->th_offset_count += delta;
 	th->th_offset_count &= th->th_counter->tc_counter_mask;
@@ -1408,4 +1595,7 @@
 	bt = th->th_offset;
 	bintime_add(&bt, &th->th_boottime);
+#ifdef FFCLOCK
+	ffclock_windup(delta, new_boottimebin, &bt);
+#endif
 	i = bt.sec - tho->th_microtime.tv_sec;
 	if (i > LARGE_STEP)
@@ -1424,4 +1614,7 @@
 	/* Now is a good time to change timecounters. */
 	if (th->th_counter != timecounter) {
+		printf("Changing tc counter on this tc-tick:  %s = %#X --> %s = %#X \n",
+			th->th_counter->tc_name, th->th_offset_count,
+			timecounter->tc_name, ncount);
 #ifndef __arm__
 		if ((timecounter->tc_flags & TC_FLAGS_C2STOP) != 0)
@@ -1435,5 +1628,5 @@
 		    (((uint64_t)timecounter->tc_counter_mask + 1) / 3));
 #ifdef FFCLOCK
-		ffclock_change_tc(th);
+		ffclock_change_tc(th,ncount);
 #endif
 	}
@@ -1478,5 +1671,5 @@
 #ifdef FFCLOCK
 	switch (sysclock_active) {
-	case SYSCLOCK_FBCK:
+	case SYSCLOCK_FB:
 #endif
 		time_second = th->th_microtime.tv_sec;
@@ -1484,7 +1677,9 @@
 #ifdef FFCLOCK
 		break;
-	case SYSCLOCK_FFWD:
-		time_second = fftimehands->tick_time_lerp.sec;
-		time_uptime = fftimehands->tick_time_lerp.sec - ffclock_boottime.sec;
+	case SYSCLOCK_FF:
+		ffclock_getbintime(&bt);
+		time_second = bt.sec;
+		ffclock_getbinuptime(&bt);
+		time_uptime = bt.sec;
 		break;
 	}
@@ -2103,5 +2298,5 @@
 		c_delta /= divi;
 		if (c_delta > cpu_tick_frequency) {
-			if (0 && bootverbose)
+	//		if (0 && bootverbose)
 				printf("cpu_tick increased to %ju Hz\n",
 				    c_delta);
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/kern/subr_rtc.c /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/subr_rtc.c
--- /usr/src/sys/kern/subr_rtc.c	2020-11-16 13:23:11.727965000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/kern/subr_rtc.c	2020-11-16 13:23:11.673689000 +1100
@@ -6,5 +6,4 @@
  *	The Regents of the University of California.
  * Copyright (c) 2011 The FreeBSD Foundation
- * All rights reserved.
  *
  * This code is derived from software contributed to Berkeley by
@@ -12,6 +11,6 @@
  * Science Department.
  *
- * Portions of this software were developed by Julien Ridoux at the University
- * of Melbourne under sponsorship from the FreeBSD Foundation.
+ * Portions of this software were developed by Julien Ridoux and Darryl Veitch
+ * at the University of Melbourne under sponsorship from the FreeBSD Foundation.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -361,10 +360,7 @@
 	}
 
-	if (ts.tv_sec >= 0) {
+	if (ts.tv_sec >= 0)
 		tc_setclock(&ts);
-#ifdef FFCLOCK
-		ffclock_reset_clock(&ts);
-#endif
-	}
+
 }
 
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/net/bpf.c /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/net/bpf.c
--- /usr/src/sys/net/bpf.c	2020-11-16 13:23:11.730662000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/net/bpf.c	2020-11-16 13:23:11.689275000 +1100
@@ -3,5 +3,5 @@
  *
  * Copyright (c) 1990, 1991, 1993
- *	The Regents of the University of California.  All rights reserved.
+ *	The Regents of the University of California.
  *
  * This code is derived from the Stanford/CMU enet packet filter,
@@ -10,4 +10,7 @@
  * Berkeley Laboratory.
  *
+ * Portions of this software were developed by Julien Ridoux and Darryl Veitch
+ * at the University of Melbourne under sponsorship from the FreeBSD Foundation.
+ *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
@@ -42,4 +45,5 @@
 #include "opt_bpf.h"
 #include "opt_ddb.h"
+#include "opt_ffclock.h"
 #include "opt_netgraph.h"
 
@@ -60,4 +64,5 @@
 #include <sys/filio.h>
 #include <sys/sockio.h>
+#include <sys/timeffc.h>
 #include <sys/ttycom.h>
 #include <sys/uio.h>
@@ -127,6 +132,11 @@
 #define PRINET  26			/* interruptible */
 
+#ifdef FFCLOCK		/* new bh_ffcounter member at end to ease ABI issues */
 #define	SIZEOF_BPF_HDR(type)	\
+    (offsetof(type, bh_ffcounter) + sizeof(((type *)0)->bh_ffcounter))
+#else
+#define	SIZEOF_BPF_HDR(type)	\
     (offsetof(type, bh_hdrlen) + sizeof(((type *)0)->bh_hdrlen))
+#endif
 
 #ifdef COMPAT_FREEBSD32
@@ -148,4 +158,5 @@
 	uint16_t	bh_hdrlen;	/* length of bpf header (this struct
 					   plus alignment padding) */
+	ffcounter	bh_ffcounter;	/* feed-forward counter stamp */
 };
 #endif
@@ -194,5 +205,9 @@
 static void	catchpacket(struct bpf_d *, u_char *, u_int, u_int,
 		    void (*)(struct bpf_d *, caddr_t, u_int, void *, u_int),
+#ifdef FFCLOCK
+		    struct bintime *, ffcounter *);
+#else
 		    struct bintime *);
+#endif
 static void	reset_d(struct bpf_d *);
 static int	bpf_setf(struct bpf_d *, struct bpf_program *, u_long cmd);
@@ -2100,46 +2115,4 @@
 }
 
-#define	BPF_TSTAMP_NONE		0
-#define	BPF_TSTAMP_FAST		1
-#define	BPF_TSTAMP_NORMAL	2
-#define	BPF_TSTAMP_EXTERN	3
-
-static int
-bpf_ts_quality(int tstype)
-{
-
-	if (tstype == BPF_T_NONE)
-		return (BPF_TSTAMP_NONE);
-	if ((tstype & BPF_T_FAST) != 0)
-		return (BPF_TSTAMP_FAST);
-
-	return (BPF_TSTAMP_NORMAL);
-}
-
-static int
-bpf_gettime(struct bintime *bt, int tstype, struct mbuf *m)
-{
-	struct m_tag *tag;
-	int quality;
-
-	quality = bpf_ts_quality(tstype);
-	if (quality == BPF_TSTAMP_NONE)
-		return (quality);
-
-	if (m != NULL) {
-		tag = m_tag_locate(m, MTAG_BPF, MTAG_BPF_TIMESTAMP, NULL);
-		if (tag != NULL) {
-			*bt = *(struct bintime *)(tag + 1);
-			return (BPF_TSTAMP_EXTERN);
-		}
-	}
-	if (quality == BPF_TSTAMP_NORMAL)
-		binuptime(bt);
-	else
-		getbinuptime(bt);
-
-	return (quality);
-}
-
 /*
  * Incoming linkage from device drivers.  Process the packet pkt, of length
@@ -2152,4 +2125,5 @@
 {
 	struct bintime bt;
+	struct sysclock_snap cs;
 	struct bpf_d *d;
 #ifdef BPF_JITTER
@@ -2157,8 +2131,8 @@
 #endif
 	u_int slen;
-	int gottime;
 
-	gottime = BPF_TSTAMP_NONE;
-
+	/* Obtain state data and tc counter timestamp for both FF and FB clocks */
+	sysclock_getsnapshot(&cs, 0);
+	
 	BPFIF_RLOCK(bp);
 
@@ -2166,8 +2140,6 @@
 		/*
 		 * We are not using any locks for d here because:
-		 * 1) any filter change is protected by interface
-		 * write lock
-		 * 2) destroying/detaching d is protected by interface
-		 * write lock, too
+		 * 1) any filter change is protected by interface write lock
+		 * 2) destroying/detaching d is protected by interface write lock, too
 		 */
 
@@ -2193,11 +2165,38 @@
 
 			counter_u64_add(d->bd_fcount, 1);
-			if (gottime < bpf_ts_quality(d->bd_tstamp))
-				gottime = bpf_gettime(&bt, d->bd_tstamp, NULL);
+			
+			/* Obtain ts if requested, no external ts in bpf_tap case */
+			if ( BPF_T_FORMAT(d->bd_tstamp)!=BPF_T_NONE ) {
+				if ( (sysclock_active==SYSCLOCK_FB
+						&& BPF_T_CLOCK(d->bd_tstamp)==BPF_T_SYSCLOCK)
+						|| BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FBCLOCK )
+					sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FB,
+						d->bd_tstamp & BPF_T_FAST,
+						d->bd_tstamp & BPF_T_MONOTONIC, 0, 0);
+				else
+					sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FF,
+						d->bd_tstamp & BPF_T_FAST,
+						d->bd_tstamp & BPF_T_MONOTONIC,
+						BPF_T_CLOCK(d->bd_tstamp)< BPF_T_FFNATIVECLOCK,
+						BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FFDIFFCLOCK );
+			}	else
+				bzero(&bt, sizeof(bt));
+
 #ifdef MAC
 			if (mac_bpfdesc_check_receive(d, bp->bif_ifp) == 0)
 #endif
-				catchpacket(d, pkt, pktlen, slen,
-				    bpf_append_bytes, &bt);
+#ifdef FFCLOCK
+			{
+				ffcounter ffcount = 0;
+				if (BPF_T_FFRAW(d->bd_tstamp) == BPF_T_FFC)
+					catchpacket(d, pkt, pktlen, slen,
+						bpf_append_mbuf, &bt, &cs.ffcount);
+				else
+					catchpacket(d, pkt, pktlen, slen,
+						bpf_append_mbuf, &bt, &ffcount);
+			}
+#else
+				catchpacket(d, pkt, pktlen, slen, bpf_append_bytes, &bt);
+#endif
 			BPFD_UNLOCK(d);
 		}
@@ -2218,10 +2217,11 @@
 {
 	struct bintime bt;
+	struct sysclock_snap cs;
 	struct bpf_d *d;
+	struct m_tag *tag;
 #ifdef BPF_JITTER
 	bpf_jit_filter *bf;
 #endif
 	u_int pktlen, slen;
-	int gottime;
 
 	/* Skip outgoing duplicate packets. */
@@ -2231,6 +2231,8 @@
 	}
 
+	/* Obtain state data and tc counter timestamp for both FF and FB clocks */
+	sysclock_getsnapshot(&cs, 0);
+
 	pktlen = m_length(m, NULL);
-	gottime = BPF_TSTAMP_NONE;
 
 	BPFIF_RLOCK(bp);
@@ -2250,13 +2252,45 @@
 		if (slen != 0) {
 			BPFD_LOCK(d);
-
+			
 			counter_u64_add(d->bd_fcount, 1);
-			if (gottime < bpf_ts_quality(d->bd_tstamp))
-				gottime = bpf_gettime(&bt, d->bd_tstamp, m);
+
+			/* Obtain ts if requested, and not already supplied externally */
+			if ( BPF_T_FORMAT(d->bd_tstamp)!=BPF_T_NONE ) {
+				tag = m_tag_locate(m, MTAG_BPF, MTAG_BPF_TIMESTAMP, NULL);
+				if (tag != NULL)	// if external ts available, use it
+					bt = *(struct bintime *)(tag + 1);
+				else
+					if ( (sysclock_active==SYSCLOCK_FB
+							&& BPF_T_CLOCK(d->bd_tstamp)==BPF_T_SYSCLOCK)
+							|| BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FBCLOCK )
+						sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FB,
+							d->bd_tstamp & BPF_T_FAST,
+							d->bd_tstamp & BPF_T_MONOTONIC, 0, 0);
+					else
+						sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FF,
+							d->bd_tstamp & BPF_T_FAST,
+							d->bd_tstamp & BPF_T_MONOTONIC,
+							BPF_T_CLOCK(d->bd_tstamp)< BPF_T_FFNATIVECLOCK,
+							BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FFDIFFCLOCK );
+			} else
+				bzero(&bt, sizeof(bt));
+				
 #ifdef MAC
 			if (mac_bpfdesc_check_receive(d, bp->bif_ifp) == 0)
 #endif
-				catchpacket(d, (u_char *)m, pktlen, slen,
-				    bpf_append_mbuf, &bt);
+#ifdef FFCLOCK
+				{
+					//printf(" ** in bpf_mtap **\n");
+					ffcounter ffcount = 0;
+					if (BPF_T_FFRAW(d->bd_tstamp) == BPF_T_FFC)
+						catchpacket(d, (u_char *)m, pktlen, slen,
+							bpf_append_mbuf, &bt, &cs.ffcount);
+					else
+						catchpacket(d, (u_char *)m, pktlen, slen,
+							bpf_append_mbuf, &bt, &ffcount);
+				}
+#else
+				catchpacket(d, (u_char *)m, pktlen, slen, bpf_append_mbuf, &bt);
+#endif
 			BPFD_UNLOCK(d);
 		}
@@ -2273,8 +2307,9 @@
 {
 	struct bintime bt;
+	struct sysclock_snap cs;
 	struct mbuf mb;
 	struct bpf_d *d;
+	struct m_tag *tag;
 	u_int pktlen, slen;
-	int gottime;
 
 	/* Skip outgoing duplicate packets. */
@@ -2284,4 +2319,7 @@
 	}
 
+	/* Obtain state data and tc counter timestamp for both FF and FB clocks */
+	sysclock_getsnapshot(&cs, 0);
+	
 	pktlen = m_length(m, NULL);
 	/*
@@ -2295,6 +2333,4 @@
 	pktlen += dlen;
 
-	gottime = BPF_TSTAMP_NONE;
-
 	BPFIF_RLOCK(bp);
 
@@ -2308,11 +2344,41 @@
 
 			counter_u64_add(d->bd_fcount, 1);
-			if (gottime < bpf_ts_quality(d->bd_tstamp))
-				gottime = bpf_gettime(&bt, d->bd_tstamp, m);
+
+			/* Obtain ts if requested, and not already supplied externally */
+			if ( BPF_T_FORMAT(d->bd_tstamp)!=BPF_T_NONE ) {
+				tag = m_tag_locate(m, MTAG_BPF, MTAG_BPF_TIMESTAMP, NULL);
+				if (tag != NULL)	// if external ts available, use it
+					bt = *(struct bintime *)(tag + 1);
+				else
+					if ( (sysclock_active==SYSCLOCK_FB
+							&& BPF_T_CLOCK(d->bd_tstamp)==BPF_T_SYSCLOCK)
+							|| BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FBCLOCK )
+						sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FB,
+							d->bd_tstamp & BPF_T_FAST,
+							d->bd_tstamp & BPF_T_MONOTONIC, 0, 0);
+					else
+						sysclock_snap2bintime(&cs, &bt, SYSCLOCK_FF,
+							d->bd_tstamp & BPF_T_FAST,
+							d->bd_tstamp & BPF_T_MONOTONIC,
+							BPF_T_CLOCK(d->bd_tstamp)< BPF_T_FFNATIVECLOCK,
+							BPF_T_CLOCK(d->bd_tstamp)==BPF_T_FFDIFFCLOCK );
+			} else
+				bzero(&bt, sizeof(bt));
 #ifdef MAC
 			if (mac_bpfdesc_check_receive(d, bp->bif_ifp) == 0)
 #endif
-				catchpacket(d, (u_char *)&mb, pktlen, slen,
-				    bpf_append_mbuf, &bt);
+#ifdef FFCLOCK
+				{
+					ffcounter ffcount = 0;
+					if (BPF_T_FFRAW(d->bd_tstamp) == BPF_T_FFC)
+						catchpacket(d, (u_char *)&mb, pktlen, slen,
+							bpf_append_mbuf, &bt, &cs.ffcount);
+					else
+						catchpacket(d, (u_char *)&mb, pktlen, slen,
+							bpf_append_mbuf, &bt, &ffcount);
+				}
+#else
+				catchpacket(d, (u_char *)&mb, pktlen, slen, bpf_append_mbuf, &bt);
+#endif
 			BPFD_UNLOCK(d);
 		}
@@ -2323,9 +2389,4 @@
 #undef	BPF_CHECK_DIRECTION
 
-#undef	BPF_TSTAMP_NONE
-#undef	BPF_TSTAMP_FAST
-#undef	BPF_TSTAMP_NORMAL
-#undef	BPF_TSTAMP_EXTERN
-
 static int
 bpf_hdrlen(struct bpf_d *d)
@@ -2359,14 +2420,7 @@
 bpf_bintime2ts(struct bintime *bt, struct bpf_ts *ts, int tstype)
 {
-	struct bintime bt2, boottimebin;
 	struct timeval tsm;
 	struct timespec tsn;
 
-	if ((tstype & BPF_T_MONOTONIC) == 0) {
-		bt2 = *bt;
-		getboottimebin(&boottimebin);
-		bintime_add(&bt2, &boottimebin);
-		bt = &bt2;
-	}
 	switch (BPF_T_FORMAT(tstype)) {
 	case BPF_T_MICROTIME:
@@ -2397,5 +2451,9 @@
 catchpacket(struct bpf_d *d, u_char *pkt, u_int pktlen, u_int snaplen,
     void (*cpfn)(struct bpf_d *, caddr_t, u_int, void *, u_int),
+#ifdef FFCLOCK
+    struct bintime *bt, ffcounter *ffcount)
+#else
     struct bintime *bt)
+#endif
 {
 	struct bpf_xhdr hdr;
@@ -2476,7 +2534,7 @@
 	caplen = totlen - hdrlen;
 	tstype = d->bd_tstamp;
-	do_timestamp = tstype != BPF_T_NONE;
+	do_timestamp = BPF_T_FORMAT(tstype) != BPF_T_NONE;
 #ifndef BURN_BRIDGES
-	if (tstype == BPF_T_NONE || BPF_T_FORMAT(tstype) == BPF_T_MICROTIME) {
+	if (BPF_T_FORMAT(tstype)==BPF_T_NONE || BPF_T_FORMAT(tstype)==BPF_T_MICROTIME) {
 		struct bpf_ts ts;
 		if (do_timestamp)
@@ -2489,4 +2547,7 @@
 				hdr32_old.bh_tstamp.tv_usec = ts.bt_frac;
 			}
+#ifdef FFCLOCK
+			hdr32_old.bh_ffcounter = *ffcount;
+#endif
 			hdr32_old.bh_datalen = pktlen;
 			hdr32_old.bh_hdrlen = hdrlen;
@@ -2502,4 +2563,7 @@
 			hdr_old.bh_tstamp.tv_usec = ts.bt_frac;
 		}
+#ifdef FFCLOCK
+		hdr_old.bh_ffcounter = *ffcount;
+#endif
 		hdr_old.bh_datalen = pktlen;
 		hdr_old.bh_hdrlen = hdrlen;
@@ -2518,4 +2582,7 @@
 	if (do_timestamp)
 		bpf_bintime2ts(bt, &hdr.bh_tstamp, tstype);
+#ifdef FFCLOCK
+	hdr.bh_ffcounter = *ffcount;
+#endif
 	hdr.bh_datalen = pktlen;
 	hdr.bh_hdrlen = hdrlen;
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/net/bpf.h /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/net/bpf.h
--- /usr/src/sys/net/bpf.h	2020-11-16 13:23:11.730922000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/net/bpf.h	2020-11-16 13:23:11.689616000 +1100
@@ -3,5 +3,5 @@
  *
  * Copyright (c) 1990, 1991, 1993
- *	The Regents of the University of California.  All rights reserved.
+ *	The Regents of the University of California.
  *
  * This code is derived from the Stanford/CMU enet packet filter,
@@ -10,4 +10,7 @@
  * Berkeley Laboratory.
  *
+ * Portions of this software were developed by Julien Ridoux and Darryl Veitch
+ * at the University of Melbourne under sponsorship from the FreeBSD Foundation.
+ *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
@@ -43,4 +46,6 @@
 #define _NET_BPF_H_
 
+#include <sys/_ffcounter.h>
+
 /* BSD style release date */
 #define	BPF_RELEASE 199606
@@ -162,30 +167,50 @@
 };
 
-/* Time stamping functions */
-#define	BPF_T_MICROTIME		0x0000
+/* Time stamping flags */
+/* FORMAT flags 	[ mutually exclusive, not to be ORed ]*/
+#define	BPF_T_MICROTIME	0x0000
 #define	BPF_T_NANOTIME		0x0001
 #define	BPF_T_BINTIME		0x0002
-#define	BPF_T_NONE		0x0003
+#define	BPF_T_NONE			0x0003	// relates to ts only, FFRAW independent
 #define	BPF_T_FORMAT_MASK	0x0003
-#define	BPF_T_NORMAL		0x0000
-#define	BPF_T_FAST		0x0100
-#define	BPF_T_MONOTONIC		0x0200
-#define	BPF_T_MONOTONIC_FAST	(BPF_T_FAST | BPF_T_MONOTONIC)
-#define	BPF_T_FLAG_MASK		0x0300
-#define	BPF_T_FORMAT(t)		((t) & BPF_T_FORMAT_MASK)
+/* FFRAW flag */
+#define	BPF_T_NOFFC			0x0000   // no FFcount
+#define	BPF_T_FFC			0x0010   // want FFcount
+#define	BPF_T_FFRAW_MASK	0x0010
+/* FLAG flags   [ can view bits as ORable flags ] */
+#define	BPF_T_NORMAL		0x0000	// UTC, !FAST
+#define	BPF_T_FAST			0x0100   // UTC,  FAST
+#define	BPF_T_MONOTONIC	0x0200	// UPTIME, !FAST
+#define	BPF_T_MONOTONIC_FAST	0x0300// UPTIME,  FAST
+#define	BPF_T_FLAG_MASK	0x0300
+/* CLOCK flags   [ mutually exclusive, not to be ORed ] */
+#define	BPF_T_SYSCLOCK		0x0000	// read current sysclock
+#define	BPF_T_FBCLOCK		0x1000   // read FB
+#define	BPF_T_FFCLOCK		0x2000   // read mono FF (standard reads are mono)
+#define	BPF_T_FFNATIVECLOCK	0x3000	// read native FF
+#define	BPF_T_FFDIFFCLOCK	0x4000	// read FF difference clock
+#define	BPF_T_CLOCK_MASK	0x7000
+
+/* Extract FORMAT, FFRAW, FLAG, CLOCK  bits */
+#define	BPF_T_FORMAT(t)	((t) & BPF_T_FORMAT_MASK)
+#define	BPF_T_FFRAW(t)		((t) & BPF_T_FFRAW_MASK)
 #define	BPF_T_FLAG(t)		((t) & BPF_T_FLAG_MASK)
-#define	BPF_T_VALID(t)						\
-    ((t) == BPF_T_NONE || (BPF_T_FORMAT(t) != BPF_T_NONE &&	\
-    ((t) & ~(BPF_T_FORMAT_MASK | BPF_T_FLAG_MASK)) == 0))
+#define	BPF_T_CLOCK(t)		((t) & BPF_T_CLOCK_MASK)
 
-#define	BPF_T_MICROTIME_FAST		(BPF_T_MICROTIME | BPF_T_FAST)
-#define	BPF_T_NANOTIME_FAST		(BPF_T_NANOTIME | BPF_T_FAST)
-#define	BPF_T_BINTIME_FAST		(BPF_T_BINTIME | BPF_T_FAST)
-#define	BPF_T_MICROTIME_MONOTONIC	(BPF_T_MICROTIME | BPF_T_MONOTONIC)
-#define	BPF_T_NANOTIME_MONOTONIC	(BPF_T_NANOTIME | BPF_T_MONOTONIC)
-#define	BPF_T_BINTIME_MONOTONIC		(BPF_T_BINTIME | BPF_T_MONOTONIC)
-#define	BPF_T_MICROTIME_MONOTONIC_FAST	(BPF_T_MICROTIME | BPF_T_MONOTONIC_FAST)
-#define	BPF_T_NANOTIME_MONOTONIC_FAST	(BPF_T_NANOTIME | BPF_T_MONOTONIC_FAST)
-#define	BPF_T_BINTIME_MONOTONIC_FAST	(BPF_T_BINTIME | BPF_T_MONOTONIC_FAST)
+/*
+ * Used to vet descriptor passed to BPF via BIOCSTSTAMP ioctl.
+ *	All components are independent, and either always meaningful, or
+ * not acted on if not meaningful. Hence checks reduce to ensuring no bits in
+ * undefined positions, and not ask for a FF clock that doesnt exist.
+*/
+#ifdef FFCLOCK
+#define	BPF_T_VALID(t)	( ((t) & ~(BPF_T_FORMAT_MASK | BPF_T_FFRAW_MASK | \
+											  BPF_T_FLAG_MASK | BPF_T_CLOCK_MASK)) == 0 \
+									&& BPF_T_CLOCK(t)<=BPF_T_FFDIFFCLOCK )
+#else
+#define	BPF_T_VALID(t)	( ((t) & ~(BPF_T_FORMAT_MASK | BPF_T_FFRAW_MASK | \
+											  BPF_T_FLAG_MASK | BPF_T_CLOCK_MASK)) == 0 \
+									&& BPF_T_CLOCK(t)<=BPF_T_FBCLOCK )
+#endif
 
 /*
@@ -202,4 +227,5 @@
 	u_short		bh_hdrlen;	/* length of bpf header (this struct
 					   plus alignment padding) */
+	ffcounter	bh_ffcounter;	/* feed-forward counter stamp */
 };
 /* Obsolete */
@@ -210,4 +236,5 @@
 	u_short		bh_hdrlen;	/* length of bpf header (this struct
 					   plus alignment padding) */
+	ffcounter	bh_ffcounter;	/* feed-forward counter stamp */
 };
 #ifdef _KERNEL
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/sys/_ffcounter.h /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/sys/_ffcounter.h
--- /usr/src/sys/sys/_ffcounter.h	2020-11-16 13:23:11.729109000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/sys/_ffcounter.h	2020-11-16 13:23:11.687593000 +1100
@@ -3,8 +3,7 @@
  *
  * Copyright (c) 2011 The University of Melbourne
- * All rights reserved.
  *
- * This software was developed by Julien Ridoux at the University of Melbourne
- * under sponsorship from the FreeBSD Foundation.
+ * This software was developed by Julien Ridoux and Darryl Veitch
+ * at the University of Melbourne under sponsorship from the FreeBSD Foundation.
  *
  * Redistribution and use in source and binary forms, with or without
diff -ar -U 2 --unidirectional-new-file /usr/src/sys/sys/timeffc.h /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/sys/timeffc.h
--- /usr/src/sys/sys/timeffc.h	2020-11-16 13:23:11.728941000 +1100
+++ /root/FFkernel_Work/FFCLOCK-FreeBSD-12.1/sys/sys/timeffc.h	2020-11-16 13:23:11.684259000 +1100
@@ -3,8 +3,7 @@
  *
  * Copyright (c) 2011 The University of Melbourne
- * All rights reserved.
  *
- * This software was developed by Julien Ridoux at the University of Melbourne
- * under sponsorship from the FreeBSD Foundation.
+ * This software was developed by Julien Ridoux and Darryl Veitch at the 
+ * University of Melbourne under sponsorship from the FreeBSD Foundation.
  *
  * Redistribution and use in source and binary forms, with or without
@@ -37,4 +36,8 @@
 #include <sys/_ffcounter.h>
 
+
+#if __BSD_VISIBLE
+#ifdef _KERNEL
+
 /*
  * Feed-forward clock estimate
@@ -44,30 +47,42 @@
  */
 struct ffclock_estimate {
-	struct bintime	update_time;	/* Time of last estimates update. */
-	ffcounter	update_ffcount;	/* Counter value at last update. */
-	ffcounter	leapsec_next;	/* Counter value of next leap second. */
-	uint64_t	period;		/* Estimate of counter period. */
-	uint32_t	errb_abs;	/* Bound on absolute clock error [ns]. */
-	uint32_t	errb_rate;	/* Bound on counter rate error [ps/s]. */
-	uint32_t	status;		/* Clock status. */
-	int16_t		leapsec_total;	/* All leap seconds seen so far. */
-	int8_t		leapsec;	/* Next leap second (in {-1,0,1}). */
+	struct bintime	update_time;	/* FFclock time of last update, ie Ca(tlast) */
+	ffcounter	update_ffcount;	/* Counter value at last update */
+	ffcounter	leapsec_expected;	/* Estimated counter value of next leap sec */
+	uint64_t	period;				/* Estimate of current counter period [2^-64 s] */
+	uint32_t	errb_abs;				/* Bound on absolute clock error [ns] */
+	uint32_t	errb_rate;			/* Bound on relative counter period err [ps/s] */
+	uint32_t	status;					/* Clock status */
+	uint16_t	secs_to_nextupdate;	/* Estimated wait til next update [s] */
+	int8_t	leapsec_total;			/* Sum of leap secs seen since clock start */
+	int8_t	leapsec_next;			/* Next leap second (in {-1,0,1}) */
 };
 
-#if __BSD_VISIBLE
-#ifdef _KERNEL
+/* Constants to hold errors and error rates in 64bit binary fraction fields */
+#define	MS_AS_BINFRAC	(uint64_t)18446744073709551ULL	// floor(2^64/1e3)
+#define	MUS_AS_BINFRAC	(uint64_t)18446744073709ULL		// floor(2^64/1e6)
+#define	NS_AS_BINFRAC	(uint64_t)18446744073ULL			// floor(2^64/1e9)
+#define	PS_AS_BINFRAC	(uint64_t)18446744ULL				// floor(2^64/1e12)
 
-/* Define the kern.sysclock sysctl tree. */
+
+/* Declare the kern.sysclock sysctl tree. */
 SYSCTL_DECL(_kern_sysclock);
 
-/* Define the kern.sysclock.ffclock sysctl tree. */
+/* Declare the kern.sysclock.ffclock sysctl tree. */
 SYSCTL_DECL(_kern_sysclock_ffclock);
 
+/* Flag defining if counter bypass mode is desired or not.
+ * This is only possible if the counter is a TSC with rdtsc defined.
+ */
+#ifdef FFCLOCK
+extern int sysctl_kern_ffclock_ffcounter_bypass;
+#endif
+
 /*
  * Index into the sysclocks array for obtaining the ASCII name of a particular
  * sysclock.
  */
-#define	SYSCLOCK_FBCK	0
-#define	SYSCLOCK_FFWD	1
+#define	SYSCLOCK_FB	0
+#define	SYSCLOCK_FF	1
 extern int sysclock_active;
 
@@ -87,4 +102,5 @@
  * control how the timecounter hardware is read and how the hardware snapshot is
  * converted into absolute time.
+ * The flags all set independent bits and so are OR-able.
  * {FB|FF}CLOCK_FAST:	Do not read the hardware counter, instead using the
  *			value at last tick. The time returned has a resolution
@@ -97,9 +113,9 @@
 #define	FFCLOCK_FAST		0x00000001
 #define	FFCLOCK_LERP		0x00000002
-#define	FFCLOCK_LEAPSEC		0x00000004
+#define	FFCLOCK_LEAPSEC	0x00000004
 #define	FFCLOCK_UPTIME		0x00000008
 #define	FFCLOCK_MASK		0x0000ffff
 
-#define	FBCLOCK_FAST		0x00010000 /* Currently unused. */
+#define	FBCLOCK_FAST		0x00010000 /* Currently unused */
 #define	FBCLOCK_UPTIME		0x00020000
 #define	FBCLOCK_MASK		0xffff0000
@@ -126,4 +142,5 @@
 	struct bintime		error;
 	struct bintime		tick_time;
+	struct bintime		tick_time_diff;
 	struct bintime		tick_time_lerp;
 	uint64_t		period;
@@ -152,9 +169,6 @@
 /* Convert a timestamp from the selected system clock into bintime. */
 int sysclock_snap2bintime(struct sysclock_snap *cs, struct bintime *bt,
-    int whichclock, uint32_t flags);
+    int whichclock, int wantFast, int wantUptime, int wantLerp, int wantDiff);
 
-/* Resets feed-forward clock from RTC */
-void ffclock_reset_clock(struct timespec *ts);
-
 /*
  * Return the current value of the feed-forward clock counter. Essential to
@@ -262,5 +276,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_bintime(bt);
 	else
@@ -272,5 +286,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_nanotime(tsp);
 	else
@@ -282,5 +296,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_microtime(tvp);
 	else
@@ -292,5 +306,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getbintime(bt);
 	else
@@ -302,5 +316,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getnanotime(tsp);
 	else
@@ -312,5 +326,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getmicrotime(tvp);
 	else
@@ -322,5 +336,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_binuptime(bt);
 	else
@@ -332,5 +346,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_nanouptime(tsp);
 	else
@@ -342,5 +356,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_microuptime(tvp);
 	else
@@ -352,5 +366,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getbinuptime(bt);
 	else
@@ -362,5 +376,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getnanouptime(tsp);
 	else
@@ -372,5 +386,5 @@
 {
 
-	if (whichclock == SYSCLOCK_FFWD)
+	if (whichclock == SYSCLOCK_FF)
 		ffclock_getmicrouptime(tvp);
 	else
