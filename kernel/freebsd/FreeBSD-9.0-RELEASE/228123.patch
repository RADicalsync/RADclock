------------------------------------------------------------------------
r228123 | lstewart | 2011-11-29 19:33:40 +1100 (Tue, 29 Nov 2011) | 13 lines

Do away with the somewhat clunky sysclock_ops structure and associated code,
reimplementing the [get]{bin,nano,micro}[up]time() wrapper functions in terms of
the new "fromclock" API instead.

Committed on behalf of Julien Ridoux and Darryl Veitch from the University of
Melbourne, Australia, as part of the FreeBSD Foundation funded "Feed-Forward
Clock Synchronization Algorithms" project.

For more information, see http://www.synclab.org/radclock/

Discussed with:	Julien Ridoux (jridoux at unimelb edu au)
Submitted by:	Julien Ridoux (jridoux at unimelb edu au)

------------------------------------------------------------------------
---
 sys/kern/kern_tc.c |  102 ++++++-----------------------------------------------
 1 file changed, 12 insertions(+), 90 deletions(-)

Index: 9.0.0/sys/kern/kern_tc.c
===================================================================
--- 9.0.0.orig/sys/kern/kern_tc.c	2012-03-15 02:47:34.000000000 +1100
+++ 9.0.0/sys/kern/kern_tc.c	2012-03-15 02:47:36.000000000 +1100
@@ -463,52 +463,20 @@ getmicrotime(struct timeval *tvp)
 
 int sysclock_active = SYSCLOCK_FBCK;
 
 /* Feed-forward clock estimates kept updated by the synchronization daemon. */
 struct ffclock_estimate ffclock_estimate;
 struct bintime ffclock_boottime;	/* Feed-forward boot time estimate. */
 uint32_t ffclock_status;		/* Feed-forward clock status. */
 int8_t ffclock_updated;			/* New estimates are available. */
 struct mtx ffclock_mtx;			/* Mutex on ffclock_estimate. */
 
-struct sysclock_ops {
-	int active;
-	void (*binuptime) (struct bintime *bt);
-	void (*nanouptime) (struct timespec *tsp);
-	void (*microuptime) (struct timeval *tvp);
-	void (*bintime) (struct bintime *bt);
-	void (*nanotime) (struct timespec *tsp);
-	void (*microtime) (struct timeval *tvp);
-	void (*getbinuptime) (struct bintime *bt);
-	void (*getnanouptime) (struct timespec *tsp);
-	void (*getmicrouptime) (struct timeval *tvp);
-	void (*getbintime) (struct bintime *bt);
-	void (*getnanotime) (struct timespec *tsp);
-	void (*getmicrotime) (struct timeval *tvp);
-};
-
-static struct sysclock_ops sysclock = {
-	.active = SYSCLOCK_FBCK,
-	.binuptime = fbclock_binuptime,
-	.nanouptime = fbclock_nanouptime,
-	.microuptime = fbclock_microuptime,
-	.bintime = fbclock_bintime,
-	.nanotime = fbclock_nanotime,
-	.microtime = fbclock_microtime,
-	.getbinuptime = fbclock_getbinuptime,
-	.getnanouptime = fbclock_getnanouptime,
-	.getmicrouptime = fbclock_getmicrouptime,
-	.getbintime = fbclock_getbintime,
-	.getnanotime = fbclock_getnanotime,
-	.getmicrotime = fbclock_getmicrotime
-};
-
 struct fftimehands {
 	struct ffclock_estimate	cest;
 	struct bintime		tick_time;
 	struct bintime		tick_time_lerp;
 	ffcounter		tick_ffcount;
 	uint64_t		period_lerp;
 	volatile uint8_t	gen;
 	struct fftimehands	*next;
 };
 
@@ -787,60 +755,20 @@ ffclock_change_tc(struct timehands *th)
 
 	/* Do not lock but ignore next update from synchronization daemon. */
 	ffclock_updated--;
 
 	if (++ogen == 0)
 		ogen = 1;
 	ffth->gen = ogen;
 	fftimehands = ffth;
 }
 
-static void
-change_sysclock(int new_sysclock)
-{
-
-	sysclock.active = new_sysclock;
-
-	switch (sysclock.active) {
-	case SYSCLOCK_FBCK:
-		sysclock.binuptime = fbclock_binuptime;
-		sysclock.nanouptime = fbclock_nanouptime;
-		sysclock.microuptime = fbclock_microuptime;
-		sysclock.bintime = fbclock_bintime;
-		sysclock.nanotime = fbclock_nanotime;
-		sysclock.microtime = fbclock_microtime;
-		sysclock.getbinuptime = fbclock_getbinuptime;
-		sysclock.getnanouptime = fbclock_getnanouptime;
-		sysclock.getmicrouptime = fbclock_getmicrouptime;
-		sysclock.getbintime = fbclock_getbintime;
-		sysclock.getnanotime = fbclock_getnanotime;
-		sysclock.getmicrotime = fbclock_getmicrotime;
-		break;
-	case SYSCLOCK_FFWD:
-		sysclock.binuptime = ffclock_binuptime;
-		sysclock.nanouptime = ffclock_nanouptime;
-		sysclock.microuptime = ffclock_microuptime;
-		sysclock.bintime = ffclock_bintime;
-		sysclock.nanotime = ffclock_nanotime;
-		sysclock.microtime = ffclock_microtime;
-		sysclock.getbinuptime = ffclock_getbinuptime;
-		sysclock.getnanouptime = ffclock_getnanouptime;
-		sysclock.getmicrouptime = ffclock_getmicrouptime;
-		sysclock.getbintime = ffclock_getbintime;
-		sysclock.getnanotime = ffclock_getnanotime;
-		sysclock.getmicrotime = ffclock_getmicrotime;
-		break;
-	default:
-		break;
-	}
-}
-
 /*
  * Retrieve feed-forward counter and time of last kernel tick.
  */
 void
 ffclock_last_tick(ffcounter *ffcount, struct bintime *bt, uint32_t flags)
 {
 	struct fftimehands *ffth;
 	uint8_t gen;
 
 	/*
@@ -942,98 +870,98 @@ ffclock_read_counter(ffcounter *ffcount)
 		*ffcount = ffth->tick_ffcount;
 	} while (gen == 0 || gen != th->th_generation);
 
 	*ffcount += delta;
 }
 
 void
 binuptime(struct bintime *bt)
 {
 
-	sysclock.binuptime(bt);
+	binuptime_fromclock(bt, sysclock_active);
 }
 
 void
 nanouptime(struct timespec *tsp)
 {
 
-	sysclock.nanouptime(tsp);
+	nanouptime_fromclock(tsp, sysclock_active);
 }
 
 void
 microuptime(struct timeval *tvp)
 {
 
-	sysclock.microuptime(tvp);
+	microuptime_fromclock(tvp, sysclock_active);
 }
 
 void
 bintime(struct bintime *bt)
 {
 
-	sysclock.bintime(bt);
+	bintime_fromclock(bt, sysclock_active);
 }
 
 void
 nanotime(struct timespec *tsp)
 {
 
-	sysclock.nanotime(tsp);
+	nanotime_fromclock(tsp, sysclock_active);
 }
 
 void
 microtime(struct timeval *tvp)
 {
 
-	sysclock.microtime(tvp);
+	microtime_fromclock(tvp, sysclock_active);
 }
 
 void
 getbinuptime(struct bintime *bt)
 {
 
-	sysclock.getbinuptime(bt);
+	getbinuptime_fromclock(bt, sysclock_active);
 }
 
 void
 getnanouptime(struct timespec *tsp)
 {
 
-	sysclock.getnanouptime(tsp);
+	getnanouptime_fromclock(tsp, sysclock_active);
 }
 
 void
 getmicrouptime(struct timeval *tvp)
 {
 
-	sysclock.getmicrouptime(tvp);
+	getmicrouptime_fromclock(tvp, sysclock_active);
 }
 
 void
 getbintime(struct bintime *bt)
 {
 
-	sysclock.getbintime(bt);
+	getbintime_fromclock(bt, sysclock_active);
 }
 
 void
 getnanotime(struct timespec *tsp)
 {
 
-	sysclock.getnanotime(tsp);
+	getnanotime_fromclock(tsp, sysclock_active);
 }
 
 void
 getmicrotime(struct timeval *tvp)
 {
 
-	sysclock.getmicrouptime(tvp);
+	getmicrouptime_fromclock(tvp, sysclock_active);
 }
 #endif /* FFCLOCK */
 
 /*
  * Initialize a new timecounter and possibly use it.
  */
 void
 tc_init(struct timecounter *tc)
 {
 	u_int u;
@@ -1261,25 +1189,20 @@ tc_windup(void)
  	 *
 	 * We happily sacrifice the lowest of the 64 bits of our result
 	 * to the goddess of code clarity.
 	 *
 	 */
 	scale = (uint64_t)1 << 63;
 	scale += (th->th_adjustment / 1024) * 2199;
 	scale /= th->th_counter->tc_frequency;
 	th->th_scale = scale * 2;
 
-#ifdef FFCLOCK
-	if (sysclock_active != sysclock.active)
-		change_sysclock(sysclock_active);
-#endif
-
 	/*
 	 * Now that the struct timehands is again consistent, set the new
 	 * generation number, making sure to not make it zero.
 	 */
 	if (++ogen == 0)
 		ogen = 1;
 	th->th_generation = ogen;
 
 	/* Go live with the new struct timehands. */
 #ifdef FFCLOCK
@@ -1634,21 +1557,20 @@ inittimecounter(void *dummy)
 	 */
 	if (hz > 1000)
 		tc_tick = (hz + 500) / 1000;
 	else
 		tc_tick = 1;
 	p = (tc_tick * 1000000) / hz;
 	printf("Timecounters tick every %d.%03u msec\n", p / 1000, p % 1000);
 
 #ifdef FFCLOCK
 	ffclock_init();
-	change_sysclock(sysclock_active);
 #endif
 	/* warm up new timecounter (again) and get rolling. */
 	(void)timecounter->tc_get_timecount(timecounter);
 	(void)timecounter->tc_get_timecount(timecounter);
 	tc_windup();
 }
 
 SYSINIT(timecounter, SI_SUB_CLOCKS, SI_ORDER_SECOND, inittimecounter, NULL);
 
 /* Cpu tick handling -------------------------------------------------*/
